{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AO6WBSvgy4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eeb62de3-8655-4bc3-c6d1-cce5a4eed5ec"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "stopwords = set(stopwords.words(\"english\"))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
        "inputs = data.Field(lower=True, tokenize='spacy', stop_words=stopwords, batch_first=True)\n",
        "answers = data.LabelField(dtype = torch.long, batch_first=True)\n",
        "\n",
        "train, dev, test = datasets.SNLI.splits(inputs, answers, root='.dataset')\n",
        "\n",
        "inputs.build_vocab(train)\n",
        "answers.build_vocab(test)\n",
        "\n",
        "train_iter, dev_iter, test_iter = data.BucketIterator.splits(   \n",
        "    (train, dev, test), batch_size=256, device=device)\n",
        "\n",
        "# z = 0\n",
        "# for batch in train_iter:\n",
        "#     z+=1\n",
        "#     print(batch.hypothesis.shape)\n",
        "#     print(batch.hypothesis)\n",
        "#     print()\n",
        "#     if z == 2:\n",
        "#         break\n",
        "\n",
        "\n",
        "# iter = data.BucketIterator(datasets.SNLI, batch_size=128, shuffle=True)\n",
        "# test_iter = iter.splits(train, batch_size=128, device=device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLJ8U7L3AHdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class LstmModel(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, output_dim, n_layers,\n",
        "                 bidirectional, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=emb_dim)\n",
        "\n",
        "        self.lstm = nn.LSTM(emb_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=bidirectional,\n",
        "                            dropout=dropout,\n",
        "                            batch_first=True)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 4, 512),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256, output_dim)\n",
        "        )\n",
        "        self.act = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "    def apply_attention(self, rnn_output, final_hidden_state):\n",
        "        '''\n",
        "        Apply Attention on RNN output\n",
        "        \n",
        "        Input:\n",
        "            rnn_output (batch_size, seq_len, num_directions * hidden_size): tensor representing hidden state for every word in the sentence\n",
        "            final_hidden_state (batch_size, num_directions * hidden_size): final hidden state of the RNN\n",
        "            \n",
        "        Returns:\n",
        "            attention_output(batch_size, num_directions * hidden_size): attention output vector for the batch\n",
        "        '''\n",
        "        # print(rnn_output.shape)\n",
        "        # print(hidden_state.shape)\n",
        "        hidden_state = final_hidden_state.unsqueeze(2)\n",
        "        attention_scores = torch.bmm(rnn_output, hidden_state).squeeze(2)\n",
        "        soft_attention_weights = F.softmax(attention_scores, 1).unsqueeze(2) #shape = (batch_size, seq_len, 1)\n",
        "        attention_output = torch.bmm(rnn_output.permute(0,2,1), soft_attention_weights).squeeze(2)\n",
        "        return attention_output\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, batch):\n",
        "        # text1 = torch.transpose(batch.hypothesis[0], 0, 1).to(device)\n",
        "        # text2 = torch.transpose(batch.premise[0], 0, 1).to(device)\n",
        "        text1 = batch.hypothesis\n",
        "        text2 = batch.premise\n",
        "        embedded1 = self.embedding(text1)\n",
        "        embedded2 = self.embedding(text2)\n",
        "        op1, (hidden1, cell) = self.lstm(embedded1)\n",
        "        op2, (hidden2, cell) = self.lstm(embedded2)\n",
        "        hidden_feature1 = torch.cat((hidden1[-1, :, :], hidden1[-2, :, :]), dim=1)\n",
        "        hidden_feature2 = torch.cat((hidden2[-1, :, :], hidden2[-2, :, :]), dim=1)\n",
        "        att1 = self.apply_attention(op1, hidden_feature1)\n",
        "        att2 = self.apply_attention(op2, hidden_feature2)\n",
        "        hidden = torch.cat((att1, att2), dim=1)\n",
        "        \n",
        "        # hidden = torch.cat((hidden1[-1, :, :], hidden2[-1, :, :]), dim=1)\n",
        "        dense_outputs = self.fc(hidden)\n",
        "        outputs = self.act(dense_outputs)\n",
        "        return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e4_5yari5m5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LstmModel(len(inputs.vocab), 200, 128, 3, 3, True, 0)\n",
        "model = model.to(device)\n",
        "# pretrained_embeds = inputs.vocab.vectors\n",
        "# model.embedding.weight.data.copy_(pretrained_embeds, non_blocking=False)\n",
        "# print(pretrained_embeds.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCLQJuNelyiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00055)\n",
        "\n",
        "def compute_accuracy(preds, y):\n",
        "    correct = (torch.argmax(preds, dim=1) == y).float()\n",
        "    accuracy = correct.sum()/len(correct)\n",
        "    return accuracy\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_T9cYFlMfi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def train_LSTM_model(model, iterator, optimizer):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        # text = torch.cat((batch.hypothesis[0], batch.premise[0]), dim=0)\n",
        "        # text = torch.transpose(text, 0, 1).to(device)\n",
        "        # text_lengths = torch.cat((batch.hypothesis[1], batch.premise[1]), dim=0)\n",
        "        pred = model(batch).squeeze()\n",
        "        loss = F.cross_entropy(pred, batch.label)\n",
        "        acc = compute_accuracy(pred, batch.label)\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def test_LSTM_model(model, iterator):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            # text = torch.cat((batch.hypothesis[0], batch.premise[0]), dim=0)\n",
        "            # text = torch.transpose(text, 0, 1).to(device)\n",
        "            # text_lengths = torch.cat((batch.hypothesis[1], batch.premise[1]), dim=0)\n",
        "            pred = model(batch).squeeze()\n",
        "            loss = F.cross_entropy(pred, batch.label)\n",
        "            acc = compute_accuracy(pred, batch.label)\n",
        "            epoch_loss += loss.item()  \n",
        "            epoch_acc += acc.item()            \n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gZV1w5mvPlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "477d878e-63a9-4f77-a726-5ce8826df4e5"
      },
      "source": [
        "num_epochs = 30\n",
        "best_valid_loss = float('inf')\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "loss_arr = []\n",
        "acc_arr = []\n",
        "\n",
        "for ep in range(num_epochs):\n",
        "    train_loss, train_acc = train_LSTM_model(model, train_iter, optimizer)\n",
        "    print(\"train loss and accuracy after \", ep, \"iterations : \", train_loss, train_acc)\n",
        "    loss_arr.append(train_loss)\n",
        "    \n",
        "    valid_loss, valid_acc = test_LSTM_model(model, test_iter)\n",
        "    print(\"test loss and accuracy after \", ep, \"iterations : \", valid_loss, valid_acc)\n",
        "    acc_arr.append(valid_acc)\n",
        "    print()\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        # torch.save(model.state_dict(), 'saved_weights4.pt')\n",
        "        for g in optimizer.param_groups:\n",
        "            g['lr'] *= 1.1\n",
        "    else:\n",
        "        for g in optimizer.param_groups:\n",
        "            g['lr'] *= 0.8\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss and accuracy after  0 iterations :  0.9321154518485181 0.5951673312656033\n",
            "test loss and accuracy after  0 iterations :  0.8828066480465424 0.6573851505915324\n",
            "\n",
            "train loss and accuracy after  1 iterations :  0.8563191144964124 0.6828517082797403\n",
            "test loss and accuracy after  1 iterations :  0.8536087687198932 0.6839610047829456\n",
            "\n",
            "train loss and accuracy after  2 iterations :  0.828651819819062 0.7132020419930478\n",
            "test loss and accuracy after  2 iterations :  0.8451120578325712 0.6969484518735837\n",
            "\n",
            "train loss and accuracy after  3 iterations :  0.8106453236806982 0.7327305137388971\n",
            "test loss and accuracy after  3 iterations :  0.8414207544082251 0.7016559839248657\n",
            "\n",
            "train loss and accuracy after  4 iterations :  0.7962500408833425 0.7483314525714458\n",
            "test loss and accuracy after  4 iterations :  0.8381359149248172 0.7051282051282052\n",
            "\n",
            "train loss and accuracy after  5 iterations :  0.7845562909211605 0.7611692270328259\n",
            "test loss and accuracy after  5 iterations :  0.8339814375608395 0.7118389423076923\n",
            "\n",
            "train loss and accuracy after  6 iterations :  0.7753590500921372 0.7705066960377884\n",
            "test loss and accuracy after  6 iterations :  0.8266935761158283 0.7170472756410257\n",
            "\n",
            "train loss and accuracy after  7 iterations :  0.7702283923412636 0.7762898196434153\n",
            "test loss and accuracy after  7 iterations :  0.8232905925848545 0.7223223829880739\n",
            "\n",
            "train loss and accuracy after  8 iterations :  0.7646807280524468 0.7820587129039622\n",
            "test loss and accuracy after  8 iterations :  0.8249147977584448 0.7175814646940964\n",
            "\n",
            "train loss and accuracy after  9 iterations :  0.7495488766910645 0.7979839210019196\n",
            "test loss and accuracy after  9 iterations :  0.820995182563097 0.7238247868342277\n",
            "\n",
            "train loss and accuracy after  10 iterations :  0.743535177127735 0.8040468983581326\n",
            "test loss and accuracy after  10 iterations :  0.8187858324784499 0.7268295945265354\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1c86bf50f510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_LSTM_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train loss and accuracy after \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iterations : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-492e64e197d1>\u001b[0m in \u001b[0;36mtrain_LSTM_model\u001b[0;34m(model, iterator, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72aXITkM417f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "76dc3d03-2984-4d7c-8e0e-3c0fb9d79432"
      },
      "source": [
        "import matplotlib.pylab as pylab\n",
        "import numpy as np\n",
        "\n",
        "def plot_loss(ep, loss_arr):\n",
        "    \n",
        "    epoch_arr = list(range(1, ep + 1))\n",
        "\n",
        "    # pylab.scatter(epoch_arr, loss_arr)\n",
        "    pylab.plot(epoch_arr, loss_arr, label = 'Loss vs Number of Epochs')\n",
        "\n",
        "    # tick_arr = np.arange(1, ep + 1, 5).tolist()\n",
        "    tick_arr = [2,4,6,8,10,12,14,16,18,20]\n",
        "    pylab.xticks(tick_arr)\n",
        "    # pylab.yscale(\"log\")\n",
        "    pylab.legend(loc='upper left')\n",
        "    pylab.xlabel(\"Number of Epochs\")\n",
        "    pylab.ylabel(\"Validation set accuracy\")\n",
        "    pylab.savefig('plot_lstm.pdf')\n",
        "\n",
        "    pylab.show()\n",
        "\n",
        "    return\n",
        "\n",
        "ep = 17\n",
        "# l = []\n",
        "# for k in loss_arr:\n",
        "#     l.append(k.item())\n",
        "acc_arr = [0.6573851505915324, 0.6839610047829456, 0.6969484518735837, 0.7016559839248657, 0.7016559839248657, 0.7118389423076923, 0.7170472756410257, 0.7223223829880739, 0.7175814646940964, 0.7238247868342277, 0.7268295945265354, .7346, .739, .7455, .7566, .7512, .755]\n",
        "plot_loss(ep, acc_arr)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKxXaWVKWGGg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "805870e6-8fa4-4533-ce89-672958324cd8"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "\n",
        "path='/content/saved_weights3.pt'\n",
        "test_model = LstmModel(len(inputs.vocab), 200, 128, 3, 2, True, 0)\n",
        "test_model.load_state_dict(torch.load(path))\n",
        "\n",
        "valid_loss, valid_acc = test_LSTM_model(model, test_iter)\n",
        "print(\"test loss and accuracy after \", ep, \"iterations : \", valid_loss, valid_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test loss and accuracy after  25 iterations :  0.7832937588939419 0.7656926412086982\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}